# Данный репозиторий посвящен предмету "Введение в проект". В этом репозитории оформлены подкаталоги, каждый из которых является отдельным модулем, рещающий некоторую задачу.


# Модуль 1 (Task 1)
## Срез данных из датасета Iris 

Этот модуль предоставляет функцию для получения подмножества строк и столбцов из датасета **Iris**, входящего в библиотеку [scikit-learn](https://scikit-learn.org/).

## Описание

Функция `get_iris_slice`:
- загружает данные Iris в формате `pandas.DataFrame`,
- выбирает первые `row_count` строк и указанные столбцы `cols` с помощью метода `.iloc[]`,
- возвращает результат в виде нового `DataFrame`.

Таким образом можно быстро получить и повторно использовать срез данных для анализа, обучения моделей или визуализации.

## Требования

- Python 3.8 или новее
- [pandas](https://pandas.pydata.org/)
- [scikit-learn](https://scikit-learn.org/)

Установка зависимостей:
```bash
pip install pandas scikit-learn
```

# Модуль 2 (Task 2)
# Создание признаков: расстояния до центра

##  Описание задачи
Задача демонстрирует приём **feature engineering** - создание нового признака на основе исходных данных.

> **Задача:**  
> Для кластеров создать признак - *расстояние до центра*.

**Baseline и метрики:**
- **Baseline:** новый признак `dist_to_center` создан.
- **Метрика:** для всех строк `dist_to_center >= 0` (положительные расстояния).

---

##  Структура решения
Основные шаги реализованы в виде отдельных функций:

| Функция | Назначение |
|---------|------------|
| `make_cluster_with_centers()` | Генерирует 2D-точки и сразу вычисляет центры кластеров. |
| `run_pipeline()` | Выполняет весь процесс: генерацию данных, расчёт расстояний и формирование итогового `DataFrame`. |
| `main()` | Пример использования `run_pipeline`: создаёт данные, печатает краткую сводку и возвращает результат. |

---

## Логика работы
1. **Генерация данных**  
   Используется `make_blobs` для создания точек в двумерном пространстве с заданным числом кластеров.
2. **Нахождение центров**  
   Для каждого кластера вычисляется среднее значение координат всех его точек.
3. **Расчёт расстояний**  
   Для каждой точки считается евклидово расстояние до центра её кластера с помощью `numpy.linalg.norm`.
4. **Формирование признака**  
   Полученное расстояние записывается в новый столбец `dist_to_center` в `pandas.DataFrame`.

---

## Пример запуска
Убедитесь, что установлен Python 3.9+ и зависимости:

```bash
pip install numpy pandas matplotlib scikit-learn
```

Клонируйте репозиторий и запустите скрипт:

```bash
python distance_to_center.py
```

---

Используемые библиотеки: **scikit-learn**, **numpy**, **pandas**, **matplotlib**.

# Модуль 3 (Task 3)  
## Создание признаков: скользящее окно с агрегацией  

### Описание задачи  
Данный модуль демонстрирует приём **feature engineering** — создание новых признаков с помощью **скользящего окна (rolling window)**.  
На основе датасета *Iris* вычисляются агрегаты (среднее, минимум, максимум, стандартное отклонение) внутри окна фиксированного размера для каждой категории `species`.

> **Задача:**  
> Для каждого вида (`species`) добавить статистические признаки по окну из 5 наблюдений:
> - `rolling mean`  
> - `rolling min`  
> - `rolling max`  
> - `rolling std`

**Baseline и метрики:**  
- **Baseline:** новые признаки успешно созданы и сохранены в CSV.  
- **Метрика:** на графиках видна динамика значений rolling-агрегатов.

---

### Структура решения  

| Функция | Назначение |
|----------|------------|
| `build_dataset_from_DA_1_07()` | Загружает исходные данные Iris через файл `DA_1_07.py` и добавляет категориальный признак `species`. |
| `compute_rolling_stats()` | Вычисляет rolling-агрегаты (`mean`, `min`, `max`, `std`) по каждой группе `species`. |
| `plot_rolling_stats()` | Строит 4 графика с динамикой rolling-показателей для каждой категории. |
| `save_dataframe_csv()` | Сохраняет итоговый DataFrame в CSV файл. |
| `main()` | Точка входа CLI: парсит аргументы, запускает всю цепочку обработки и рисует графики. |

---

### Логика работы  
1. **Загрузка данных**  
   Используются функции из `DA_1_07.py`: `load_iris_dataset()` и `create_categorical_feature()`.  
2. **Расчёт скользящих статистик**  
   Для выбранного числового признака (`sepal length (cm)`) внутри каждой группы `species` вычисляются `mean`, `min`, `max`, `std` в окне из 5 наблюдений.  
3. **Добавление новых признаков**  
   Результаты добавляются в тот же DataFrame в виде новых столбцов:  
   - `<value_col>_roll_mean5`  
   - `<value_col>_roll_min5`  
   - `<value_col>_roll_max5`  
   - `<value_col>_roll_std5`  
4. **Визуализация**  
   Для каждой статистики строится отдельный график, показывающий изменение показателя по индексу наблюдений внутри вида.  
5. **Сохранение результата**  
   Итоговая таблица записывается в CSV-файл `iris_DA-3-29_roll_features.csv`.

---

### Пример запуска  
Убедитесь, что рядом находятся файлы `DA_1_07.py` и `compute_rolling_features.py`, а также установлены зависимости:  

```bash
pip install pandas matplotlib scikit-learn
```

Запустите модуль:  
```bash
python compute_rolling_features.py
```

или с параметрами CLI:  
```bash
python compute_rolling_features.py   --value-col "sepal length (cm)"   --group-col species   --window 5   --min-periods 1   --out-csv iris_DA-3-29_roll_features.csv   --no-show
```

---

### Используемые библиотеки  
- **pandas** — обработка и агрегация данных  
- **matplotlib** — построение графиков  
- **scikit-learn** — загрузка датасета Iris  

---

### Результат работы  
- Файл `iris_DA-3-29_roll_features.csv` с новыми rolling-признаками.  
- 4 графика, иллюстрирующих динамику `mean`, `min`, `max`, `std` по времени внутри каждого вида Iris.